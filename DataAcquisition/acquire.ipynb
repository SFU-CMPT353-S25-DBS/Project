{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Data Acquisition\n",
    "\n",
    "This code downloads the [bchydro-outages](https://github.com/outages/bchydro-outages/tree/main) project (including all commit history) from GitHub and saves it to a sub directory.\n",
    "\n",
    "Then it does some work to process it into a usable Pandas-compatible format.\n",
    "\n",
    "See BC Hydro's frontend here: https://www.bchydro.com/power-outages/app/outage-map.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be wary of how much compute big numbers require\n",
    "# 14 days took ~30 seconds to run on my computer, plus ~15 seconds to download the repo - Bea\n",
    "# 90 days took ~10 minutes to run on my less good laptop - Bea\n",
    "# The file size of the CSV will probably never be more than 200Mb\n",
    "# 150 days took ~2 minutes and 52 sec to run on my mac m1 air, total size 18.9 MB - Soumya\n",
    "DAYS_TO_CAPTURE = 9\n",
    "\"\"\"The number of days of history to capture in the returned Pandas Data\"\"\"\n",
    "\n",
    "DELETE_OLD_REPO = False\n",
    "\"\"\"If True, deletes the old repository data and starts fresh\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "target = os.getcwd()\n",
    "repoName = \"bchydro-outages\"\n",
    "\n",
    "repoPath = os.path.join(target, repoName)\n",
    "\n",
    "if DELETE_OLD_REPO and os.path.exists(repoPath):\n",
    "  # https://stackoverflow.com/a/6996628 <-- How to delete a directory in Python\n",
    "  shutil.rmtree(repoPath)\n",
    "\n",
    "# https://stackoverflow.com/a/4760517 <-- How to run subprocess in Python\n",
    "\n",
    "# Clone the REPO and save to <repoName> folder under DataAcquisition/\n",
    "result = subprocess.run(\n",
    "  [\"git\", \"clone\", \"https://github.com/outages/bchydro-outages.git\", f\"./{repoName}\"],\n",
    "  cwd=target,\n",
    "  capture_output=True,\n",
    ")\n",
    "print(result.stdout.decode(\"utf-8\"))\n",
    "print(result.stderr.decode(\"utf-8\"))\n",
    "\n",
    "# Confirm that the repository was cloned\n",
    "assert os.path.exists(repoPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process commit history\n",
    "\n",
    "The repo only has 1 file in it: a `.json` file which shows the current (right now) outages being tracked by BC Hydro. To find historical data, we need to traverse the commit history and merge each commit together\n",
    "\n",
    "\n",
    "### Step 1) Get the JSON data from each commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Reset to main branch\n",
    "subprocess.run([\"git\", \"checkout\", \"main\"], cwd=repoPath)\n",
    "\n",
    "# Find the oldest commit from N days ago\n",
    "afterTime = f\"{DAYS_TO_CAPTURE} days ago\"\n",
    "\n",
    "commitLog = subprocess.run(\n",
    "  [\"git\", \"log\", f\"--since={afterTime}\", \"--pretty=format:%H:%ct\", \"--reverse\"],\n",
    "  cwd=repoPath,\n",
    "  capture_output=True,\n",
    ")\n",
    "commits = commitLog.stdout.decode(\"utf-8\")\n",
    "\n",
    "commits = [commit.split(\":\") for commit in commits.split(\"\\n\")]\n",
    "\n",
    "# Get JSON file for each commit\n",
    "\n",
    "OUTAGES_FILE_NAME = \"bchydro-outages.json\"\n",
    "outagesFilePath = os.path.join(repoPath, OUTAGES_FILE_NAME)\n",
    "\n",
    "\n",
    "def getJSON(commit):\n",
    "  subprocess.run([\"git\", \"checkout\", commit[0]], cwd=repoPath, capture_output=True)\n",
    "  assert os.path.exists(os.path.join(repoPath, outagesFilePath))\n",
    "  with open(outagesFilePath, \"r\") as f:\n",
    "    # https://stackoverflow.com/q/20199126 <-- How to load JSON from a file\n",
    "    return json.load(f)\n",
    "\n",
    "\n",
    "jsonData = [getJSON(commit) for commit in commits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2) Combine the JSON data\n",
    "\n",
    "Because this tracks current outages, we never actually get to see the \"timeOn\" at the end. The `dateOn` field in the JSON is only an estimate time. \n",
    "\n",
    "But, we can interpret when the outage ended (within +-15 minutes) by seeing if it is present in the next commit. This is why we'll start from the latest commit and work towards present-day\n",
    "\n",
    "This does mean that the most recent outages (any that are still ongoing) won't be added to the list, but that's fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to take all but start time from the latest entry for an outage\n",
    "outages = []\n",
    "\n",
    "\n",
    "waitingForEndTime = []\n",
    "for i, data in enumerate(jsonData):\n",
    "  commitTime = commits[i][1]\n",
    "\n",
    "  # data is a list of active outages\n",
    "  activeOutageIds = [outage[\"id\"] for outage in data]\n",
    "\n",
    "  # Check if any of the outages in waitingForEndTime are in the active outages\n",
    "  # Push to final array if they aren't\n",
    "\n",
    "  newWaiting = []\n",
    "  for waitingOutage in waitingForEndTime:\n",
    "    if waitingOutage[\"id\"] not in activeOutageIds:\n",
    "      waitingOutage[\"endTime\"] = commitTime\n",
    "      outages.append(waitingOutage)\n",
    "    else:\n",
    "      newWaiting.append(waitingOutage)\n",
    "  waitingForEndTime = newWaiting\n",
    "\n",
    "  # Override any outages waiting for time with latest data\n",
    "  for i, waitingOutage in enumerate(waitingForEndTime):\n",
    "    for outage in data:\n",
    "      if waitingOutage[\"id\"] == outage[\"id\"]:\n",
    "        waitingForEndTime[i] = outage\n",
    "        break\n",
    "\n",
    "  # Add any new outages to waitingForEndTime\n",
    "  for outage in data:\n",
    "    if outage[\"id\"] not in [waitingOutage[\"id\"] for waitingOutage in waitingForEndTime]:\n",
    "      waitingForEndTime.append(outage)\n",
    "\n",
    "print(f\"Raw Outages Indexed: {len(outages)}\")\n",
    "print(f\"Active Outages (Not recorded): {len(waitingForEndTime)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3) Cleanup \n",
    "\n",
    "Delete unneeded fields and convert all times to proper datetime objects\n",
    "\n",
    "Some terminology:\n",
    "- \"eta\" is the estimated time of arrival for the repair crew\n",
    "- \"etr\" is the estimated time of restoration for the power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from common import timeStampFields\n",
    "\n",
    "pdOutages = pd.DataFrame(outages)\n",
    "\n",
    "# dateOn is BC Hydro's estimate of when power would be restored, `endTime` is the actual measure time from when it was removed from the active outages page\n",
    "# So let's rename `dateOn` to `estDateOn` and `endTime` to `dateOn`\n",
    "pdOutages.rename(\n",
    "  {\"dateOn\": \"estDateOn\", \"endTime\": \"dateOn\"}, axis=\"columns\", inplace=True\n",
    ")\n",
    "\n",
    "# Let's delete the columns that aren't useful\n",
    "pdOutages.drop(\n",
    "  columns=[\n",
    "    \"showEta\",  # Only useful for BC Hydro's website\n",
    "    \"showEtr\",  # Only useful for BC Hydro's website\n",
    "    \"crewStatusNote\",  # Not specified format (and usually empty)\n",
    "    \"crewStatusDescription\",  # Doesn't update once outage is resolved\n",
    "    \"crewStatus\",  # Doesn't update once outage is resolved\n",
    "  ],\n",
    "  inplace=True\n",
    ")\n",
    "\n",
    "# Convert to datetime (some timestamps are in ms unix and some are in s unix so this accounts for that)\n",
    "for field, unit in timeStampFields:\n",
    "  pdOutages[field] = pd.to_datetime(pdOutages[field], unit=unit, utc=True)\n",
    "\n",
    "# Sort\n",
    "pdOutages = pdOutages.sort_values(by=['dateOff', 'dateOn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import csvFileName\n",
    "\n",
    "pdOutages.to_csv(csvFileName, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
