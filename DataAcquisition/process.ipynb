{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data from acquire\n",
    "\n",
    "import pandas as pd\n",
    "from common import timeStampFields, csvFileName\n",
    "\n",
    "timeFields = [t[0] for t in timeStampFields]\n",
    "\n",
    "pdOutages = pd.read_csv(csvFileName, header='infer', parse_dates=timeFields)\n",
    "\n",
    "# Convert the time fields to America/Vancouver timezone\n",
    "for field in timeFields:\n",
    "  pdOutages[field] = pdOutages[field].dt.tz_convert('America/Vancouver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Duplicates\n",
    "\n",
    "Sometimes, outages are duplicated in BC Hydro's own data (ie, the same outage is reported twice __with two different IDs__)\n",
    "\n",
    "We should be able to fix this, though, by grouping all outages that have overlapping start and end times with an identical location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "removedDups = 0\n",
    "\n",
    "def matchIntervals(areaEntries: pd.DataFrame):\n",
    "  # Group into intervals\n",
    "  # https://stackoverflow.com/a/48243958\n",
    "  intervals = (\n",
    "    (\n",
    "      areaEntries[\"dateOn\"]\n",
    "      .apply(lambda x: x.timestamp())\n",
    "      .rolling(window=2, min_periods=1)\n",
    "      .min()\n",
    "      - areaEntries[\"dateOff\"]\n",
    "      .apply(lambda x: x.timestamp())\n",
    "      .rolling(window=2, min_periods=1)\n",
    "      .max()\n",
    "    )\n",
    "    < 0\n",
    "  ).cumsum()\n",
    "\n",
    "  areaEntries[\"interval\"] = intervals\n",
    "\n",
    "  global removedDups\n",
    "  removedDups += intervals.count() - len(intervals.unique())\n",
    "\n",
    "  return areaEntries\n",
    "\n",
    "\n",
    "mergedPdOutages = (\n",
    "  pdOutages.groupby(by=[\"area\"])\n",
    "  .apply(matchIntervals)\n",
    "  .reset_index(drop=True)\n",
    "  .groupby(by=[\"area\", \"interval\"])\n",
    "  .aggregate(\n",
    "    {\n",
    "      \"id\": \"first\",  # Maybe not the best idea, perhaps combine ids?\n",
    "      \"gisId\": \"first\",\n",
    "      \"regionId\": \"first\",\n",
    "      \"municipality\": \"first\",\n",
    "      \"area\": \"first\",\n",
    "      \"cause\": \"first\",\n",
    "      \"numCustomersOut\": \"max\",\n",
    "      \"crewEta\": \"max\",\n",
    "      \"crewEtr\": \"max\",\n",
    "      \"dateOff\": \"min\",\n",
    "      \"dateOn\": \"max\",\n",
    "      \"estDateOn\": \"max\",\n",
    "      \"lastUpdated\": \"max\",\n",
    "      \"regionName\": \"first\",\n",
    "      \"latitude\": \"first\",\n",
    "      \"longitude\": \"first\",\n",
    "      \"polygon\": \"last\",\n",
    "      \"interval\": \"max\"\n",
    "    }\n",
    "  )\n",
    "  .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Merged {removedDups} outages with overlapping start/end times and areas\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
