{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests relating to the distance to the nearest station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "# Allow importing from parent directory by temporarily moving the CWD up one level\n",
    "# Very hacky, but there literally isn't a simpler way (in Jupyter)\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from common import get_dataframe_from_pipeline\n",
    "outages = get_dataframe_from_pipeline(\"../pipeline/3.csv.gz\")\n",
    "# Drop the path back down after import\n",
    "sys.path.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the distances are normally distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.normaltest(outages['outageToSubstationDistance']).pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Idea\n",
    "1. Splitting the distances into **equal** length **bins** and seeing how many outages occured that have distances in that distance interval for example from (0,3), is the number of outages that had a distance of between 0 to 3 to the nearest station.\n",
    "2. Now we **groupby** these intervals and aggregate by counting the number of outages that are in this interval. This gives us outages per distance\n",
    "3. We can do a statistical test like a **T-test** to see if there is a significant different between the first half of these outages compared to the second half of these outages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cuts the data into 3 equal width bins.\n",
    "data = pd.Series([2,19,1,20, 13, 19, 24, 30])\n",
    "bins = pd.cut(data, bins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200 #number of bins\n",
    "distance_bins = pd.cut(outages['outageToSubstationDistance'], bins=n)\n",
    "outages['distance_bin'] = distance_bins\n",
    "outages_per_dist = outages.groupby(['distance_bin']).size().reset_index(name=\"# of outages\")\n",
    "outages_per_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outages['outageToSubstationDistance'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Test:\n",
    "Doing a T-test comparing the first half of the bins to the second half of the bins.\n",
    "<p> Checking for equal variances: since the levene test p-value is very small. We can proceed as them having different variances, which is why we have chosen \"equal_var=False\" when doing the t-test.\n",
    "<p> According to the big p-value, since the ttest alternative hypothesis is that \"the mean of the distribution underlying the first sample is greater than the mean of the distribution underlying the second sample.\", it means it is strongly rejecting it!! so we cannot conclude that there is more number of outages that are far compared to closer ones!\n",
    "\n",
    "### Note that these results are still not valid because the welch's t test assumes normality!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_bin = n//2\n",
    "\n",
    "closer_outages = outages_per_dist[outages_per_dist['distance_bin'].cat.codes < median_bin]['# of outages'].reset_index(drop=True)\n",
    "farther_outages = outages_per_dist[outages_per_dist['distance_bin'].cat.codes >= median_bin]['# of outages'].reset_index(drop=True)\n",
    "closer_outages = closer_outages.to_frame()\n",
    "farther_outages = farther_outages.to_frame()\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(farther_outages['# of outages'], closer_outages['# of outages'], equal_var=False, alternative='greater')\n",
    "print(\"Levene Test p-value:\", stats.levene(farther_outages['# of outages'], closer_outages['# of outages']).pvalue)\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying a Mann-Whitney U-test: \n",
    "The result of this also agrees with the t test result and strongly aggress with the null hypothesis, so it disagrees strongly with the alternative hypothesis.\n",
    "Since the alternative hypothesis is: \"the distribution underlying x is stochastically greater than the distribution underlying y, i.e. SX(u) > SY(u) for all u\", It shows that it is not true that farther outages have more outages compared to smaller ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.mannwhitneyu(farther_outages['# of outages'], closer_outages['# of outages'], alternative='greater').pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for correlations: **distance vs timeout**\n",
    "Checking if there is any correlation between the distance of the outage to the station and the time it took for the outage to be resolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outages['timeOut'] = outages['dateOn'] - outages['dateOff']\n",
    "outages['timeOut'] = outages['timeOut'].apply(lambda x: x.total_seconds()/3600)\n",
    "#timeout is the total of hours without power (we can change it into hours if its better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.normaltest(outages['timeOut']).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = stats.linregress(outages['timeOut'], outages['outageToSubstationDistance'])\n",
    "plt.plot(outages[\"timeOut\"], outages[\"outageToSubstationDistance\"], 'b.', alpha = 0.5)\n",
    "plt.plot(outages[\"timeOut\"], outages[\"timeOut\"]*fit.slope + fit.intercept, 'r-', linewidth = 3)\n",
    "plt.title('Timeout vs Distance')\n",
    "plt.ylabel('Distance (km)')\n",
    "plt.xlabel('TimeOut (hour)')\n",
    "plt.show()\n",
    "#this plot doesnt look good because the distance csv that I created was not very good. \n",
    "#it would be nice to try it on our actual big dataset and the corresponding distances csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outages[\"timeOut\"].corr(outages[\"outageToSubstationDistance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outages[\"timeOut\"].apply(np.sqrt).corr(outages[\"outageToSubstationDistance\"].apply(np.sqrt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log transformation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outages[\"timeOut\"].apply(np.log).corr(outages[\"outageToSubstationDistance\"].apply(np.log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeouts_transformed = outages[\"timeOut\"].apply(np.log)\n",
    "distance_transformed = outages[\"outageToSubstationDistance\"].apply(np.log)\n",
    "fit = stats.linregress(timeouts_transformed, distance_transformed)\n",
    "plt.loglog(outages[\"timeOut\"], outages[\"outageToSubstationDistance\"], 'b.', alpha=0.5)\n",
    "\n",
    "# Regression line\n",
    "x_vals = np.linspace(outages[\"timeOut\"].min(), outages[\"timeOut\"].max(), 100) #evenly spaced over the interval of timeout values.\n",
    "y_vals = np.exp(fit.intercept) * x_vals ** fit.slope\n",
    "plt.loglog(x_vals, y_vals, 'r-', linewidth=3)\n",
    "\n",
    "plt.title('Timeout vs Distance (log-log scale)')\n",
    "plt.xlabel('TimeOut (hour)')\n",
    "plt.ylabel('Distance (km)')\n",
    "plt.grid(True, which=\"both\", ls=\"--\", linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important: These fitted lines cannot be trusted because the residuals are not normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = outages[\"outageToSubstationDistance\"]\n",
    "x = outages[\"timeOut\"]\n",
    "residuals = y - (fit.slope*x + fit.intercept)\n",
    "plt.hist(residuals, bins = 90)\n",
    "plt.title(\"plot of the residuals\", fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using spearmann's correlation test:\n",
    "doesnt need normality. Below, we have used the alternative hypothesis of the correlation being less than 0, since the p value is around 1, its very likely that there is a positive relation between them!\n",
    "we can proceed with them having a small positive correlation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho, pval = spearmanr(outages['timeOut'], outages['outageToSubstationDistance'],alternative = 'less')\n",
    "print(f\"Spearman correlation: {rho:.3f}, p-value: {pval:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: very cool finding\n",
    "comparing the distance to substations, and the distance to cities, versus timeout, the distances to cities have a higher spearman correlation to timeouts compared to distance to substations.\n",
    "suggesting distances to cities to be more of a factor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outages in different **municipalities**:\n",
    "similar to the analysis in tests-cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outages_per_municipality = outages.groupby('outageMunicipality').size().reset_index(name = 'outage_count')\n",
    "distances_per_municipality = outages.groupby('outageMunicipality')['outageToSubstationDistance'].mean().reset_index(name='mean_distance')\n",
    "municipality_stats = pd.merge(outages_per_municipality, distances_per_municipality, on='outageMunicipality')\n",
    "municipality_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.normaltest(municipality_stats['mean_distance']).pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using spearmann's correlation test:\n",
    "doesnt need normality. Below, we have used the alternative hypothesis of the correlation being less than 0, since the p value is 0.948, its very likely that there is a positive relation between them!\n",
    "we can proceed with them having a small positive correlation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho, pval = spearmanr(municipality_stats['mean_distance'], municipality_stats['outage_count'],alternative = 'less')\n",
    "print(f\"Spearman correlation: {rho:.3f}, p-value: {pval:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation tests\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html\n",
    "Spearmann suggests using the permutation tests for <500 data points. \n",
    "<p>\n",
    "since we have around 350 regions, its good to try that too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic(x): # permute only `x`\n",
    "\n",
    "    return stats.spearmanr(x, y).statistic\n",
    "\n",
    "x = municipality_stats['mean_distance']\n",
    "y = municipality_stats['outage_count']\n",
    "res_exact = stats.permutation_test((x,), statistic,\n",
    "\n",
    "    permutation_type='pairings', alternative = 'less')\n",
    "\n",
    "res_asymptotic = stats.spearmanr(x, y, alternative = 'less')\n",
    "\n",
    "res_exact.pvalue, res_asymptotic.pvalue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
